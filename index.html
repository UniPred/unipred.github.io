<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="">
  <meta name="keywords" content="Robotic, Planning, Predicate, Foundation Models, LLM, Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>UniPred</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* Ensure the main demo is truly centered and not constrained oddly by surrounding elements */
    .unipred-video-wrap {
      display: flex;
      justify-content: center;
    }
    .unipred-video {
      width: 100%;
      max-width: 960px;
      border-radius: 12px;
      overflow: hidden;
    }
    .unipred-video video {
      width: 100%;
      height: auto;
      display: block;
    }
  </style>
</head>

<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>

  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
      </a>

      <a class="navbar-item" href="#demos">Demos</a>
      <a class="navbar-item" href="#recovery">Failure Recovery</a>
      <a class="navbar-item" href="#fails">Failures</a>
      <a class="navbar-item" href="#bibtex">BibTeX</a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">UniPred: Unifying Deep Predicate Invention with Foundation Models</h1>
          <!-- <div class="subtitle">Unifying Deep Predicate Invention with Foundation Models</div> -->


         <div class="is-size-6 publication-authors has-text-centered">
  <span class="author-block">
    <a href="https://weiqianwang123.github.io/" target="_blank" rel="noopener">Qianwei Wang</a><sup>1,2,∗</sup>,
  </span>
  <span class="author-block">
    <a href="https://jaraxxus-me.github.io/" target="_blank" rel="noopener">Bowen Li</a><sup>1,∗</sup>,
  </span>
  <span class="author-block">
    <a href="https://zhanpeng1202.github.io/" target="_blank" rel="noopener">Zhanpeng Luo</a><sup>1,3</sup>,
  </span>
  <span class="author-block">
    <a href="https://scholar.google.com/citations?user=RYKMFp4AAAAJ&hl=en" target="_blank" rel="noopener">Yifan Xu</a><sup>2</sup>,
  </span>
  <span class="author-block">
    <a href="https://scholar.google.com/citations?user=yZDEX68AAAAJ&hl=en" target="_blank" rel="noopener">Alexander Gray</a><sup>4</sup>,
  </span>
  <span class="author-block">
    <a href="https://tomsilver.github.io/" target="_blank" rel="noopener">Tom Silver</a><sup>5</sup>,
  </span>
  <span class="author-block">
    <a href="https://www.ri.cmu.edu/ri-faculty/sebastian-scherer/" target="_blank" rel="noopener">Sebastian Scherer</a><sup>1</sup>,
  </span>
  <span class="author-block">
    <a href="https://www.ri.cmu.edu/ri-faculty/katia-sycara/" target="_blank" rel="noopener">Katia Sycara</a><sup>1</sup>,
  </span>
  <span class="author-block">
    <a href="https://yaqi-xie.me/" target="_blank" rel="noopener">Yaqi Xie</a><sup>1,†</sup>
  </span>
</div>

<div class="is-size-7 publication-authors has-text-centered">
  <span class="author-block"><sup>1</sup>Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA</span><br>
  <span class="author-block"><sup>2</sup>Computer Science and Engineering Division, University of Michigan</span><br>
  <span class="author-block"><sup>3</sup>Department of Computer Science, University of Pittsburgh</span><br>
  <span class="author-block"><sup>4</sup>Centaur AI Institute</span><br>
  <span class="author-block"><sup>5</sup>Department of Electrical and Computer Engineering, Princeton University</span>
</div>

<div class="is-size-7 content has-text-centered" style="margin-top: 10px;">
  <p style="margin-bottom: 6px;">∗ Equal Contribution. † Corresponding author.</p>
  <p style="margin-bottom: 6px;">Contact: <a href="mailto:bowenli2@andrew.cmu.edu">bowenli2@andrew.cmu.edu</a>.</p>
  <p style="max-width: 980px; margin: 0 auto;">
    The work was partly done when Qianwei Wang and Zhanpeng Luo were Robotics Institute Summer Scholars associated with the Advanced Agent Robotics Technology Lab, CMU.
  </p>
</div>


          <div class="column has-text-centered">
            <div class="publication-links">

              <span class="link-block">
                <a href="./static/unipred.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://arxiv.org/pdf/2512.17992"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- <span class="link-block">
                <a href="https://youtube.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->

              <span class="link-block">
                <a href="https://github.com/weiqianwang123/UniPred"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
<!-- 
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a>
              </span> -->

            </div>
          </div>

          <!-- <div class="content has-text-centered" style="margin-top: 16px;">
            <p style="max-width: 920px; margin: 0 auto;">
              Unifying Deep Predicate Invention with Foundation Models for Long Horizon Planning
            </p>
          </div> -->

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="unipred-video-wrap">
        <div class="unipred-video">
          <video autoplay muted loop playsinline>
            <source src="./static/videos/main_demo.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <h2 class="subtitle has-text-centered" style="margin-top: 16px;">
        UniPred performs long horizon planning with a learned neural-symbolic world model
      </h2>
    </div>
  </div>
</section>

<section class="section" id="abstract">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Long horizon robotic tasks are hard due to contin
        uous state action spaces and sparse feedback. Symbolic world
        models help by decomposing tasks into discrete predicates that
        capture object properties and relations. Existing methods learn
        predicates either top down, by prompting foundation models
        without data grounding, or bottom up, from demonstrations
        without high level priors. We introduce UniPred, a bilevel
        learning framework that unifies both. UniPred uses large lan
        guage models (LLMs) to propose predicate effect distributions
        that supervise neural predicate learning from low level data,
        while learned feedback iteratively refines the LLM hypotheses.
        Leveraging strong visual foundation model features, UniPred
        learns robust predicate classifiers in cluttered scenes. We further
        propose a predicate evaluation method that supports symbolic
        models beyond STRIPS assumptions. Across five simulated and
        one real robot domains, UniPred achieves 2 ∼ 4× higher success
        rates than top down methods and 3 ∼ 4× faster learning than
        bottom up approaches, advancing scalable and flexible symbolic
        world modeling for robotics.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section" id="overview">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Overview of UniPred</h2>

        <div class="content">
          <p>
            UniPred is a novel framework that integrates deep learning and symbolic reasoning for long-horizon planning tasks in robotics. By leveraging large language models (LLMs) and visual foundation models, UniPred can effectively learn and reason about complex object properties and relationships in cluttered environments.
          </p>

          <!-- 如果你想放一张方法图 -->
          
          <figure class="image">
            <img src="./static/images/framework.png" alt="UniPred overview">
          </figure>
          <p class="has-text-centered is-size-7">Figure 1: Overview of UniPred framework.</p>

          <figure class="image">
            <img src="./static/images/learning.png" alt="UniPred overview">
          </figure>
          <p class="has-text-centered is-size-7">Figure 2: Overview of unified bilevel learning.</p>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small" id="demos">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered" style="margin-bottom: 18px;">Demo Videos</h2>

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item" style="position:relative; height:80%; display:flex; justify-content:center; align-items:center;">
          <video autoplay controls muted loop playsinline style="width:100%; height:100%; object-fit:cover;">
            <source src="./static/videos/main_demo_1.mp4" type="video/mp4">
          </video>
        </div>


       <div class="item" style="position:relative; height: 80%; display:flex; justify-content:center; align-items:center;">
        <video autoplay controls muted loop playsinline style="width:100%; height:100%; object-fit:cover;">
          <source src="./static/videos/main_demo_2.mp4" type="video/mp4">
        </video>
      </div>


      
    </div>
  </div>
</section>

<section class="section" id="recovery">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Some failures UniPred can recover</h2>

        <div class="content">
          <div class="unipred-video-wrap">
            <div class="unipred-video">
              <video autoplay controls muted loop playsinline>
                <source src="./static/videos/recover_main.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <p style="margin-top: 12px;">
            UniPred continuously replans based on observation feedback, detects action failures during execution, and performs recovery replanning. Through a total of 13 steps, the system successfully completes the task.
          </p>
        </div>

        <div class="columns is-centered" style="margin-top: 10px;">
          <div class="column">
            <div class="content">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/recover_1.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <div class="column">
            <div class="content">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/recover_3.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section" id="fails">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Some failures cannot</h2>

        <div class="columns is-centered">
          <div class="column">
            <video autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fail1.mp4" type="video/mp4">
            </video>
          </div>

          <div class="column">
            <video autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fail2.mp4" type="video/mp4">
            </video>
          </div>

          <div class="column">
            <video autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fail3.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="content" style="margin-top: 10px;">
          <p>
            Long horizon manipulation tasks are inherently challenging. Many unpredictable factors can lead to failure, including planning failures and accumulated execution errors at each action step.
          </p>
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section" id="bibtex">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc
    {
      wang2025unifyingdeeppredicateinvention,
      title={Unifying Deep Predicate Invention with Pre-trained Foundation Models}, 
      author={Qianwei Wang and Bowen Li and Zhanpeng Luo and Yifan Xu and Alexander Gray and Tom Silver and Sebastian Scherer and Katia Sycara and Yaqi Xie},
      year={2025},
      eprint={2512.17992},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2512.17992}, 
    }
  </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="./static/unipred_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Template credit: Nerfies website template
          </p>
          <p>
            Reminder: do not include analytics snippets if you do not want tracking
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
